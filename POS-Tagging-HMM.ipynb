{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of words(M):  55907\n",
      "Number of tags(N):  12\n",
      "{'DET': 136724, 'NOUN': 275075, 'ADJ': 83581, 'VERB': 182380, 'ADP': 144483, '.': 147231, 'ADV': 56115, 'CONJ': 38067, 'PRT': 29759, 'PRON': 49174, 'NUM': 14853, 'X': 1369}\n"
     ]
    }
   ],
   "source": [
    "from nltk.corpus import treebank,brown\n",
    "\n",
    "corpus = brown.tagged_sents(tagset='universal')[:-100] \n",
    "#print(corpus[0])\n",
    "tag_dict={}\n",
    "word_dict={}\n",
    "\n",
    "for sent in corpus:\n",
    "    for elem in sent:\n",
    "        w = elem[0]\n",
    "        tag= elem[1]\n",
    "        if w not in word_dict:\n",
    "            word_dict[w]=0\n",
    "        if tag not in tag_dict:\n",
    "            tag_dict[tag]=0\n",
    "        word_dict[w]+=1\n",
    "        tag_dict[tag]+=1\n",
    "\n",
    "print('Number of words(M): ',len(word_dict))\n",
    "print('Number of tags(N): ',len(tag_dict))\n",
    "print(tag_dict)\n",
    "        \n",
    "test_data= brown.tagged_sents(tagset='universal')[-10:]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('START', 'START'), ('DET', 'The'), ('NOUN', 'Fulton'), ('NOUN', 'County'), ('ADJ', 'Grand'), ('NOUN', 'Jury'), ('VERB', 'said'), ('NOUN', 'Friday'), ('DET', 'an'), ('NOUN', 'investigation'), ('ADP', 'of'), ('NOUN', \"Atlanta's\"), ('ADJ', 'recent'), ('NOUN', 'primary'), ('NOUN', 'election'), ('VERB', 'produced'), ('.', '``'), ('DET', 'no'), ('NOUN', 'evidence'), ('.', \"''\"), ('ADP', 'that'), ('DET', 'any'), ('NOUN', 'irregularities'), ('VERB', 'took'), ('NOUN', 'place'), ('.', '.'), ('END', 'END'), ('START', 'START'), ('DET', 'The'), ('NOUN', 'jury')]\n"
     ]
    }
   ],
   "source": [
    "brown_tags_words = [ ]\n",
    "for sent in corpus:  \n",
    "    brown_tags_words.append( (\"START\", \"START\") )\n",
    "    brown_tags_words.extend([ (tag, word) for (word, tag) in sent ])\n",
    "    brown_tags_words.append( (\"END\", \"END\") )\n",
    "    \n",
    "print(brown_tags_words[0:30])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "State Transition matrix:\n",
      "[[0.005917029928907872, 0.6263860039203066, 0.23980427723004008, 0.06470700096544864, 0.009091308036628536, 0.012748310464878149, 0.017502413621602646, 0.0006436324273719318, 0.002011351335537287, 0.009895848570843451, 0.009764196483426465, 0.0013969749275913519], [0.01550122693810779, 0.14934835953830775, 0.012894665091338726, 0.1589093883486322, 0.24437698809415614, 0.2835844769608289, 0.026370989730073617, 0.0596782695628465, 0.01782786512769245, 0.01978369535581205, 0.008077796964464238, 0.0003308188675815687], [0.005850611981191898, 0.65281583134923, 0.05690288462688889, 0.01746808485182039, 0.08844115289360022, 0.10033380792285328, 0.009643339993539201, 0.037604240198131154, 0.019286679987078403, 0.003804692454026633, 0.006987233940728156, 0.0004905421088524905], [0.16292904923785503, 0.0975710055927185, 0.05753920386007238, 0.1843020067989911, 0.1691797346200241, 0.08060642614321746, 0.10326241912490404, 0.014376576378988924, 0.06559381511130606, 0.054923785502796356, 0.008975764886500712, 0.00018094089264173704], [0.4555968522248292, 0.25848023642919926, 0.08268792868365137, 0.041257448973235605, 0.020293044856488307, 0.0097450911179862, 0.015489711592367268, 0.0018894956500072673, 0.014230047825695757, 0.06968985970667829, 0.03013503318729539, 0.000449879916668397], [0.0677031331716826, 0.08292411244914454, 0.028920539831964735, 0.07657354769036412, 0.06516290726817042, 0.10723964382500968, 0.043564195040446646, 0.06929926442121565, 0.018331737202083802, 0.046247053949236235, 0.012076261113488328, 0.001256528856015377], [0.07361668003207698, 0.032861088835427245, 0.13622026196204223, 0.24031007751937986, 0.14204758086073244, 0.17000801924619086, 0.09687249398556536, 0.017321571772253408, 0.028655439721999465, 0.048329323710237904, 0.013311948676824378, 8.910273545397844e-05], [0.1511282738329787, 0.24380697191793416, 0.11211810754721938, 0.19536606509575222, 0.07334436651167678, 0.02075288307457903, 0.09136522447264034, 0.0002626947224630257, 0.02503480705072635, 0.06753881314524392, 0.01867759476712113, 0.000551658917172354], [0.08363856312376088, 0.03578749285930307, 0.018918646459894484, 0.6225007560737928, 0.09066164857690111, 0.07658187439094055, 0.036123525656104036, 0.012231593803555227, 0.01125709869283242, 0.0068214657750596455, 0.00510769851137471, 6.720655936019356e-05], [0.0175499247569854, 0.008886810102899906, 0.00951722454955871, 0.7064098914060276, 0.0555781510554358, 0.10357099280107374, 0.05403261886362712, 0.01142880383942734, 0.023752389474112335, 0.008195387806564444, 0.0009761255948265344, 0.0], [0.013128660876590587, 0.38025988015889045, 0.05917996364370834, 0.04551269103884737, 0.1310846293678045, 0.2710563522520703, 0.02039991920824076, 0.038308759173231, 0.005251464350636235, 0.008483134720258533, 0.021746448528916718, 0.00020197939810139365], [0.005113221329437546, 0.0547845142439737, 0.0029218407596785976, 0.052593133674214754, 0.053323593864134405, 0.2731921110299489, 0.006574141709276844, 0.022644265887509132, 0.007304601899196494, 0.006574141709276844, 0.0007304601899196494, 0.5127830533235939]]\n"
     ]
    }
   ],
   "source": [
    "import nltk\n",
    "\n",
    "# conditional frequency distribution of the word given the tags\n",
    "CFD_tag_words = nltk.ConditionalFreqDist(brown_tags_words)\n",
    "# conditional probability distribution of the word given the tags\n",
    "# P(wi | ti)\n",
    "CPD_tag_words = nltk.ConditionalProbDist(CFD_tag_words, nltk.MLEProbDist)\n",
    "\n",
    "brown_tags = [tag for (tag, word) in brown_tags_words ]\n",
    "\n",
    "# make conditional frequency distribution: count(t{i-1} ti)\n",
    "CFD_tags= nltk.ConditionalFreqDist(nltk.bigrams(brown_tags))\n",
    "# make conditional probability distribution, using maximum likelihood estimate:\n",
    "# P(ti | t{i-1})\n",
    "CPD_tags = nltk.ConditionalProbDist(CFD_tags, nltk.MLEProbDist)\n",
    "\n",
    "tag_trans_matrix=[]\n",
    "j=-1\n",
    "for tag1 in tag_dict:\n",
    "    tag_trans_matrix.append([])\n",
    "    j=j+1\n",
    "    for tag2 in tag_dict:\n",
    "        tag_trans_matrix[j].append(CPD_tags[tag1].prob(tag2))\n",
    "print(\"State Transition matrix:\")\n",
    "print(tag_trans_matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{'PRT': 0.0, 'DET': 0.0, 'NOUN': 0.0, 'VERB': 0.0, '.': 0.0, 'X': 0.0, 'ADP': 0.0, 'ADV': 0.0, 'PRON': 0.008857092757255521, 'ADJ': 0.0, 'NUM': 0.0, 'END': 0.0, 'CONJ': 0.0}]\n",
      "[{'PRT': 'START', 'DET': 'START', 'NOUN': 'START', 'VERB': 'START', '.': 'START', 'X': 'START', 'ADP': 'START', 'ADV': 'START', 'PRON': 'START', 'ADJ': 'START', 'NUM': 'START', 'END': 'START', 'CONJ': 'START'}]\n",
      "\n",
      "The given sentence: ['you', \"can't\", 'very', 'well', 'sidle', 'up', 'to', 'people', 'on', 'the', 'street', 'and', 'ask', 'if', 'they', 'want', 'to', 'buy', 'a', 'hot', 'Bodhisattva', '.']\n",
      "\n",
      "The POS tags: ['PRON', 'VERB', 'ADV', 'ADV', 'VERB', 'PRT', 'ADP', 'NOUN', 'ADP', 'DET', 'NOUN', 'CONJ', 'VERB', 'ADP', 'PRON', 'VERB', 'PRT', 'VERB', 'DET', 'ADJ', 'NOUN', '.']\n"
     ]
    }
   ],
   "source": [
    "def Viterbi(sentence):\n",
    "    sentlen = len(sentence)\n",
    "    distinct_tags = set(brown_tags)\n",
    "\n",
    "    viterbi = [ ]\n",
    "    backpointer = [ ]\n",
    "\n",
    "    viterbi_init = { }\n",
    "    backpointer_init = { }\n",
    "\n",
    "    for tag in distinct_tags:\n",
    "        if tag == \"START\": continue\n",
    "        print()\n",
    "        viterbi_init[ tag ] = CPD_tags[\"START\"].prob(tag) * CPD_tag_words[tag].prob(sentence[0])\n",
    "        backpointer_init[ tag ] = \"START\"\n",
    "    viterbi.append(viterbi_init)\n",
    "    backpointer.append(backpointer_init)\n",
    "    print(viterbi)\n",
    "    print(backpointer)\n",
    "\n",
    "    for wordindex in range(1, len(sentence)):\n",
    "        cur_viterbi = { }\n",
    "        cur_backpointer = { }\n",
    "        prev_viterbi = viterbi[-1]\n",
    "            \n",
    "        for tag in distinct_tags:\n",
    "            if tag == \"START\": continue\n",
    "            if sentence[wordindex] not in word_dict.keys():\n",
    "                best_prevtag = max(prev_viterbi.keys(),key = lambda prevtag: \\\n",
    "                    prev_viterbi[ prevtag ] * CPD_tags[prevtag].prob(tag) *0.0001)\n",
    "                cur_viterbi[tag] = prev_viterbi[ best_prevtag ] *\\\n",
    "                                    CPD_tags[best_prevtag].prob(tag) * 0.0001\n",
    "            else:\n",
    "                best_prevtag = max(prev_viterbi.keys(),key = lambda prevtag: \\\n",
    "                    prev_viterbi[ prevtag ] * CPD_tags[prevtag].prob(tag) * \n",
    "                                    CPD_tag_words[tag].prob(sentence[wordindex]))\n",
    "                cur_viterbi[tag] = prev_viterbi[ best_prevtag ] *\\\n",
    "                                    CPD_tags[best_prevtag].prob(tag) *\\\n",
    "                                    CPD_tag_words[tag].prob(sentence[wordindex])\n",
    "            cur_backpointer[tag] = best_prevtag\n",
    "\n",
    "        viterbi.append(cur_viterbi)\n",
    "        backpointer.append(cur_backpointer)\n",
    "\n",
    "    prev_viterbi = viterbi[-1]\n",
    "    best_prevtag = max(prev_viterbi.keys(),key = lambda prevtag: prev_viterbi[ prevtag ] *\\\n",
    "                       CPD_tags[prevtag].prob(\"END\"))\n",
    "\n",
    "    prob_best_seq = prev_viterbi[ best_prevtag ] * CPD_tags[ best_prevtag].prob(\"END\")\n",
    "    best_tag_seq = [ \"END\", best_prevtag ]\n",
    "\n",
    "    backpointer.reverse()\n",
    "    current_best_tag = best_prevtag\n",
    "    for bp in backpointer:\n",
    "        best_tag_seq.append(bp[current_best_tag])\n",
    "        current_best_tag = bp[current_best_tag]\n",
    "\n",
    "    best_tag_seq.reverse()\n",
    "    \n",
    "    return best_tag_seq[1:-1]\n",
    "    \n",
    "#sentence = ['I', \"can't\", 'drive', 'a', 'car', '.']\n",
    "sentence = ['you', \"can't\", 'very', 'well', 'sidle', 'up', 'to', 'people', 'on', 'the', 'street', 'and', 'ask', 'if', 'they', 'want', 'to', 'buy', 'a', 'hot', 'Bodhisattva', '.']\n",
    "\n",
    "tag_seq=Viterbi(sentence)\n",
    "print(\"\\nThe given sentence:\",sentence)\n",
    "print(\"\\nThe POS tags:\",tag_seq)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
